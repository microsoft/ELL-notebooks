{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with image classification on a Raspberry Pi\n",
    "\n",
    "In this tutorial, we will download a pre-trained image classifier from the ELL Gallery. First, we will choose a model and try it out on Azure, to see it classify images. Then we can download the notebook to Jupyter running on your laptop or desktop machine. Running the notebook on your local machine allows the notebook to connect directly to your Raspberry Pi over your local network.\n",
    "\n",
    "![screenshot](https://microsoft.github.io/ELL/tutorials/Getting-Started-with-Image-Classification-on-the-Raspberry-Pi/Screenshot.png)\n",
    "\n",
    "Our first step is to install the `ell` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!conda config --prepend channels conda-forge --prepend channels microsoft-ell\n",
    "!conda install -y ell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a pre-trained model\n",
    "\n",
    "The [ELL Gallery](https://microsoft.github.io/ELL/gallery) contains a number of pretrained Deep Neural Networks for image classification. These models vary in the size of the image input that they accept and their network architectures. To get started, instantiate the ModelGallery class, which allows us to choose one of the available models. If you are unfamiliar with these networks, feel free to stick with the default choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ell.util.gallery import ModelGallery\n",
    "gallery = ModelGallery()\n",
    "gallery.choose_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the selections above, the `gallery` object has a field `model` with our choice of model. Download this model to the Azure Notebook. The `download` method has parameters to name a local directory in which to download the model. By default, a model has a complicated name that reflects its architecture. The optional `rename` parameter gives the model a simpler name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = gallery.model\n",
    "pretrained_model.download('getting-started', rename='model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If you like, you can repeat the last steps of Part 1 to build the model on the host machine and try it to make predictions on that machine. Here, let's look at building the model for the Rapsberry Pi and making predictions on that device.\n",
    "\n",
    "## Compile the model for the Raspberry Pi\n",
    "\n",
    "We are ready to cross-compile the model for deployment on the Raspberry Pi. Use the `compile` method and specify the target platform as `PI3`. This tells the ELL compiler to generate machine code for the Raspberry Pi's ARM Cortex A53 processor. The `compile` method creates a new directory named `pi3`, which contains a CMake project that can be used to build the desired Python module. This time, we need to build this project on the Raspberry Pi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ell.platform\n",
    "pretrained_model.compile(ell.platform.PI3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write code to invoke the model on the Raspberry Pi\n",
    "\n",
    "Deploy the model to the Raspberry Pi and try it out by using the Jupyter \"magic\" called `%%rpi`. This magic requires several arguments: The name of the user on the Raspberry Pi (typically \"pi\"), the Pi's IP address on the local network, the directory where the model will be downloaded, and the Python variable that refers to our model. **Change the `ip` and `user` arguments to your Raspberry Pi's IP address and your user name before running the code in the cell below.**\n",
    "\n",
    "Running this cell does several things. First, it prompts for the user password on the Pi. (This password is remembered during a notebook session, so it only needs to be entered once.) Second, it downloads the code from the local `pi3` directory to the directory on the Pi specified by `rpipath`. Next, it builds the CMake project on the Pi. (Again, this is only necessary once per model.) Finally, it runs the cell's Python code on the Pi. Any output that the Python code prints will be shown in the notebook. Also, because the Python code could contain a loop, we provide a button to allow you to stop the code running on the Pi.\n",
    "\n",
    "Just like in Part 1, start by downloading a known image and run the model on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%rpi --user=pi --ip=157.54.156.73 --rpipath=/home/pi/mymodel --model=pretrained_model\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import tutorialHelpers as helpers\n",
    "import sys\n",
    "sys.path.append('build')\n",
    "import model\n",
    "\n",
    "urllib.request.urlretrieve('https://microsoft.github.io/ELL/tutorials/shared/coffeemug.jpg', 'coffeemug.jpg')\n",
    "image = cv2.imread(\"coffeemug.jpg\")\n",
    "\n",
    "inputShape = model.get_default_input_shape()\n",
    "outputShape = model.get_default_output_shape()\n",
    "predictions = model.FloatVector(outputShape.Size())\n",
    "\n",
    "categories = [line.strip('\\n') for line in open('categories.txt', 'r').readlines()]\n",
    "\n",
    "input = helpers.prepare_image_for_model(image, inputShape.columns, inputShape.rows)\n",
    "model.predict(input, predictions)\n",
    "top5 = helpers.get_top_n(predictions, 5)\n",
    "text = \"\".join([\"(\" + str(int(conf * 100)) + \"%) \" + categories[index] for (index, conf) in top5])\n",
    "print('TOP 5:')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After seeing it work on a static image, run the cell below to classify an object in a web cam image. This code works like a camera: when you run the cell, it causes the Pi to take a web cam image and runs that image through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%rpi --user=pi --ip=157.54.156.73 --rpipath=/home/pi/mymodel --model=pretrained_model\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import tutorialHelpers as helpers\n",
    "import sys\n",
    "sys.path.append('build')\n",
    "import model\n",
    "\n",
    "def get_image_from_camera(camera):\n",
    "    if camera is not None:\n",
    "        # if predictor is too slow frames get buffered, this is designed to flush that buffer\n",
    "        ret, frame = camera.read()\n",
    "        if (not ret):\n",
    "            raise Exception('your capture device is not returning images')\n",
    "        return frame\n",
    "    return None\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "image = get_image_from_camera(camera)\n",
    "\n",
    "inputShape = model.get_default_input_shape()\n",
    "outputShape = model.get_default_output_shape()\n",
    "predictions = model.FloatVector(outputShape.Size())\n",
    "\n",
    "categories = [line.strip('\\n') for line in open('categories.txt', 'r').readlines()]\n",
    "\n",
    "input = helpers.prepare_image_for_model(image, inputShape.columns, inputShape.rows)\n",
    "model.predict(input, predictions)\n",
    "top5 = helpers.get_top_n(predictions, 5)\n",
    "text = \"\".join([\"(\" + str(int(conf * 100)) + \"%) \" + categories[index] for (index, conf) in top5])\n",
    "print('TOP 5:')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you like, you can also add a loop around this code to classify one web cam image after another. To stop the code from running on the Pi, click the Stop button that appears."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
